{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d6ceaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd1d8e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Error connecting to server",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m     h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m               encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1286\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1332\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1331\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m \n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 979\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1458\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1456\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[1;32m-> 1458\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mwrap_socket(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock,\n\u001b[0;32m   1459\u001b[0m                                       server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    512\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    514\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msslsocket_class\u001b[38;5;241m.\u001b[39m_create(\n\u001b[0;32m    518\u001b[0m         sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[0;32m    519\u001b[0m         server_side\u001b[38;5;241m=\u001b[39mserver_side,\n\u001b[0;32m    520\u001b[0m         do_handshake_on_connect\u001b[38;5;241m=\u001b[39mdo_handshake_on_connect,\n\u001b[0;32m    521\u001b[0m         suppress_ragged_eofs\u001b[38;5;241m=\u001b[39msuppress_ragged_eofs,\n\u001b[0;32m    522\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[0;32m    523\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    524\u001b[0m         session\u001b[38;5;241m=\u001b[39msession\n\u001b[0;32m    525\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1075\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1074\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1075\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1346\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1346\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1002)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ucimlrepo\\fetch.py:66\u001b[0m, in \u001b[0;36mfetch_ucirepo\u001b[1;34m(name, id)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     response  \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(api_url)\n\u001b[0;32m     67\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(response)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    537\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    495\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[0;32m   1392\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context, check_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_hostname)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1352\u001b[0m r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1002)>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m###Task 1: Import the adult dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m   \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# fetch dataset \u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m adult \u001b[38;5;241m=\u001b[39m fetch_ucirepo(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# data (as pandas dataframes) \u001b[39;00m\n\u001b[0;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m adult\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfeatures \n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ucimlrepo\\fetch.py:69\u001b[0m, in \u001b[0;36mfetch_ucirepo\u001b[1;34m(name, id)\u001b[0m\n\u001b[0;32m     67\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(response)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError):\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError connecting to server\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# verify that dataset exists \u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "\u001b[1;31mConnectionError\u001b[0m: Error connecting to server"
     ]
    }
   ],
   "source": [
    "###Task 1: Import the adult dataset\n",
    "\n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets #income\n",
    "  \n",
    "# metadata \n",
    "print(adult.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(adult.variables) \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5df7489",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd368dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #concatenate x and y horizontally (along columns)\n",
    "# concatenated_data = pd.concat([X, y], axis = 1)\n",
    "# concatenated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cf724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###Task 2:\n",
    "print(X.head)\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(X.shape)\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(X.info)\n",
    "print(\"------------------------------------------------------------------------------\")\n",
    "print(X.describe)\n",
    "print(\"------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a7d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Task 2.1: Plot a histogram of the data\n",
    "\n",
    "X.hist(figsize=(24, 16))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc122615",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 3: check for the number of these missing values \n",
    "missing_values_count = X.isna().sum().sum()\n",
    "\n",
    "print(f\"Total number of missing values: {missing_values_count}\")\n",
    "\n",
    "missing_values_by_feature = X.apply(lambda x: (x == '?').sum())\n",
    "\n",
    "print(missing_values_by_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c1b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Task 4: Replace the missing values with null.\n",
    "\n",
    "# Make a copy of the DataFrame\n",
    "X = X.copy()\n",
    "\n",
    "# Replace missing values represented as '?' with NaN in the copied DataFrame\n",
    "X.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Check non-null count using X_copy.info()\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d18a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Task 5: Create and apply a preprocessing pipeline\n",
    "\n",
    "# Define the numeric and categorical columns\n",
    "num_cols = X.select_dtypes(include='number').columns.to_list()\n",
    "cat_cols = X.select_dtypes(exclude='number').columns.to_list()\n",
    "\n",
    "# Exclude the target from numerical columns\n",
    "# cat_cols.remove(\"income\")\n",
    "\n",
    "# Create pipelines for numeric and categorical columns\n",
    "num_pipeline = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler())\n",
    "cat_pipeline = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder())\n",
    "\n",
    "\n",
    "#Preprocessing for numerical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ])\n",
    "\n",
    "# Create and apply the preprocessing pipeline\n",
    "X_prepared = preprocessor.fit_transform(X)\n",
    "\n",
    "preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000eaef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfefc4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming adult_prepared is a NumPy array or a Pandas DataFrame\n",
    "feature_names=preprocessor.get_feature_names_out()\n",
    "adult_prepared = pd.DataFrame(data=adult_prepared, columns=feature_names)\n",
    "adult_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_prepared.shape:\", X_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Task 6: Check the target value_counts. You will notice that the target needs some data cleaning\n",
    "\n",
    "target_value_counts = y.value_counts()\n",
    "\n",
    "# Display the current target value counts\n",
    "print(\"Current Target Value Counts:\")\n",
    "print(target_value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Task 7: Remove the period at the end of the >50K. and <=50K.\n",
    "\n",
    "# Create a new DataFrame with the modified values\n",
    "y_cleaned = y.copy()\n",
    "y_cleaned['income'] = y_cleaned['income'].str.strip('. ')\n",
    "\n",
    "# After removing the period, recheck the target value counts\n",
    "target_value_counts = y_cleaned['income'].value_counts()\n",
    "\n",
    "# Display the cleaned target value counts\n",
    "print(\"\\nCleaned Target Value Counts:\")\n",
    "print(target_value_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8e7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Task 8: Split the data into 80% training set and 20% testing set, print the shape of X_train, X_test, y_train, y_test in one command.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into an 80% training set and a 20% testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_prepared, y_cleaned, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of X_train, X_test, y_train, and y_test\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95418640",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Task 9: Train a svm model (svc) to predict if the income of the adult exceeds 50K on the training set\n",
    " \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create and train the SVM model\n",
    "\n",
    "model_svm = SVC(kernel='poly', C=0.1, gamma=1)\n",
    "model_svm.fit(X_train[:10000],y_train[:10000].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ada0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###Task 9.1: Test your model on the X_Test, and report the classification_report on the y_test and y_predict.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Use the trained SVM model to make predictions on the X_test data\n",
    "y_predict = model_svm.predict(X_test)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_predict)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)\n",
    "\n",
    "###Task 9.2: Display the confusion matrix of your test results\n",
    "\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "# conf_matrix = confusion_matrix(y_test, y_predict)\n",
    "\n",
    "# # Get the unique classes from the 'income' column in y_test DataFrame\n",
    "# unique_classes = y_test['income'].unique()\n",
    "\n",
    "# # Display the confusion matrix with the correct labels\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=unique_classes)\n",
    "# disp.plot(cmap='Blues')\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad59537",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Task 10: Use GridSearchCV to find the best value of kernel, gamma, and C. \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Flatten the target variable y using .values.ravel()\n",
    "y_train_flattened = y_train.values.ravel()\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': [0.1, 1, 10],\n",
    "    'C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "\n",
    "# Fit the grid search to the data with the flattened y_train\n",
    "print(X_train[:100].shape)\n",
    "grid_search.fit(X_train[:10000], y_train_flattened[:10000])\n",
    "\n",
    "# Get the best combination of parameters\n",
    "best_params = grid_search.best_params_\n",
    "best_kernel = best_params['kernel']\n",
    "best_gamma = best_params['gamma']\n",
    "best_C = best_params['C']\n",
    "\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best kernel:\", best_kernel)\n",
    "print(\"Best gamma:\", best_gamma)\n",
    "print(\"Best C:\", best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe69725",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Task 10.1: Split the dataset into 60% training, 20% validation, and 20% testing.\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_validation_test, y_train, y_validation_test = train_test_split(X_prepared, y, test_size=0.4, random_state=42)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_validation_test, y_validation_test, test_size=0.5, random_state=42)\n",
    "\n",
    "print(X_train.shape,y_train.shape, X_validation.shape, y_validation.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf2170",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Task 10.2: Use the below code snippet to pass the following hyperparameters for theGridSearchCV to find the best ones.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm_parameters = {'kernel': ['rbf'],\n",
    "                   'C': [0.01, 0.1, 1, 10],\n",
    "                    'gamma': [0.01, 1, 10]\n",
    "                 }\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "svm_gs = GridSearchCV(estimator = svm,\n",
    "                      param_grid = svm_parameters)\n",
    "\n",
    "#svm_gs.fit(X.train.iloc[:10000], y_train.iloc[:10000].values.ravel())\n",
    "svm_gs.fit(X_train[:100], y_train[:100].values.ravel())\n",
    "\n",
    "\n",
    "# svm_winner = svm.gs.best_estimator_\n",
    "# svm_winner.score(X_validation, y_validation)\n",
    "svm_winner = svm_gs.best_estimator_\n",
    "svm_winner.score(X_validation, y_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e7c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Task 10.2: Check the svm winner parameters using svm_winner\n",
    "\n",
    "svm_winner_params = grid_search.best_params_\n",
    "\n",
    "# Print the winning hyperparameters\n",
    "print(\"Winning Hyperparameters for SVM:\")\n",
    "print(svm_winner_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df418ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
